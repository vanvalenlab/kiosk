helmDefaults:
  wait: true
  timeout: 600
  force: true

releases:

#######################################################################################
## prometheus-operator                                                               ##
## creates/configures/manages Prometheus clusters atop Kubernetes                    ##
#######################################################################################

#
# References:
#   - https://github.com/coreos/prometheus-operator/tree/master/helm/prometheus-operator
#   - https://github.com/coreos/prometheus-operator
#
- name: prometheus-operator
  namespace: monitoring
  labels:
    chart: prometheus-operator
    repo: stable
    component: monitoring
    namespace: monitoring
    vendor: coreos
    default: true
  chart: stable/prometheus-operator
  version: 7.5.0
  wait: true
  values:
    # A list of all possible values can be found:
    # https://github.com/helm/charts/blob/master/stable/prometheus-operator/values.yaml
    - additionalPrometheusRulesMap:
      - name: custom-prometheus-rules
        groups:
          - name: custom-redis-metrics
            rules:
            - record: avg_gpu_usage
              expr: avg(container_accelerator_duty_cycle)
              labels:
                namespace: deepcell
                service: gpu-average-service
            - record: tf_serving_scale_metric
              expr: avg_over_time(avg_gpu_usage[30s])
              labels:
                namespace: deepcell
                service: tf-serving-scaling-service
            - record: tf_serving_up
              expr: |-
                clamp_max(
                  clamp_min(
                    kube_deployment_status_replicas_available{deployment="tf-serving"}
                  , 0)
                , 1)
                or on()
                up{service="kubernetes"} * on() 0
              labels:
                namespace: deepcell
                service: tf-serving-running-service
            - record: segmentation_consumer_key_ratio
              # COMPLICATED scaling metric that prevents too many consumers
              # per GPU.  If too many consumers, scale down slightly.
              # Structural outline follows:
              # (
              #   min(1 - GPU, keys/consumers) * !is_too_many_consumers
              #   +
              #   .9 * target * is_too_many_consumers)
              # ) * is_tf_up
              expr: |-
                (
                  (
                    (100 - tf_serving_scale_metric) / 100
                    < on()
                    clamp_max(
                      (
                        avg_over_time(redis_script_values{key="segmentation_image_keys"}[30s])
                        / on()
                        (
                          avg_over_time(kube_deployment_status_replicas_available{deployment="segmentation-consumer"}[30s])
                          *
                          100
                        )
                      )
                    , 1)
                    or
                    clamp_max(
                      (
                        avg_over_time(redis_script_values{key="segmentation_image_keys"}[30s])
                        / on()
                        (
                          avg_over_time(kube_deployment_status_replicas_available{deployment="segmentation-consumer"}[30s])
                          *
                          100
                        )
                      )
                    , 1)
                  )
                  * on()
                  (
                    clamp_max(
                      clamp_min(
                        avg_over_time(kube_deployment_status_replicas_available{deployment="segmentation-consumer"}[30s])
                      , 0)
                      / on()
                      clamp_min(
                        avg_over_time(kube_deployment_status_replicas_available{deployment="tf-serving"}[30s])
                      , 1)
                      <= on()
                      150
                      or on()
                      up{service="kubernetes"} * on() 0
                    , 1)
                  )
                  + on()
                  (
                    clamp_max(
                      clamp_min(
                        avg_over_time(kube_deployment_status_replicas_available{deployment="segmentation-consumer"}[30s])
                      , 0)
                      / on()
                      clamp_min(
                        avg_over_time(kube_deployment_status_replicas_available{deployment="tf-serving"}[30s])
                      , 0)
                      > on()
                      150
                      or on()
                      up{service="kubernetes"} * on() 0
                    , 1)
                    * on()
                    .9 * .15
                  )
                )
                * on()
                tf_serving_up
              labels:
                namespace: deepcell
                service: segmentation-scaling-service
            - record: zip_consumer_key_ratio
              expr: |-
                avg_over_time(redis_script_values{key="segmentation_zip_keys"}[30s])
                / on()
                (
                  avg_over_time(kube_deployment_spec_replicas{deployment="zip-consumer"}[30s])
                  +
                  1
                )
              labels:
                namespace: deepcell
                service: zip-scaling-service
            - record: tracking_consumer_key_ratio
              expr: |-
                avg_over_time(redis_script_values{key="tracking_image_keys"}[30s])
                / on()
                (
                  avg_over_time(kube_deployment_spec_replicas{deployment="tracking-consumer"}[30s])
                  +
                  1
                )
              labels:
                namespace: deepcell
                service: tracking-scaling-service

      ## Configuration for alertmanager
      ## ref: https://prometheus.io/docs/alerting/alertmanager/
      ##
      alertmanager:

        ## Deploy alertmanager
        ##
        enabled: true

        ## Pass the Alertmanager configuration directives through Helm's templating
        ## engine. If the Alertmanager configuration contains Alertmanager templates,
        ## they'll need to be properly escaped so that they are not interpreted by
        ## Helm
        ## ref: https://helm.sh/docs/developing_charts/#using-the-tpl-function
        ##      https://prometheus.io/docs/alerting/configuration/#%3Ctmpl_string%3E
        ##      https://prometheus.io/docs/alerting/notifications/
        ##      https://prometheus.io/docs/alerting/notification_examples/
        tplConfig: false

        ## Alertmanager template files to format alerts
        ## ref: https://prometheus.io/docs/alerting/notifications/
        ##      https://prometheus.io/docs/alerting/notification_examples/
        ##
        templateFiles: {}
        #
        ## An example template:
        #   template_1.tmpl: |-
        #       {{ define "cluster" }}{{ .ExternalURL | reReplaceAll ".*alertmanager\\.(.*)" "$1" }}{{ end }}
        #
        #       {{ define "slack.myorg.text" }}
        #       {{- $root := . -}}
        #       {{ range .Alerts }}
        #         *Alert:* {{ .Annotations.summary }} - `{{ .Labels.severity }}`
        #         *Cluster:*  {{ template "cluster" $root }}
        #         *Description:* {{ .Annotations.description }}
        #         *Graph:* <{{ .GeneratorURL }}|:chart_with_upwards_trend:>
        #         *Runbook:* <{{ .Annotations.runbook }}|:spiral_note_pad:>
        #         *Details:*
        #           {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
        #           {{ end }}

      ## Using default values from https://github.com/helm/charts/blob/master/stable/grafana/values.yaml
      ##
      grafana:

        dashboards:
          default:
            prometheus-stats:
              # Ref: https://grafana.com/dashboards/2
              gnetId: 2
              revision: 2
              datasource: Prometheus
            prometheus-redis:
              # Ref: https://grafana.com/dashboards/763
              gnetId: 763
              revision: 2
              datasource: Prometheus

      ## Deploy a Prometheus instance
      ##
      prometheus:

        ## Settings affecting prometheusSpec
        ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
        ##
        prometheusSpec:

          ## Interval between consecutive scrapes.
          ##
          scrapeInterval: 30s

          ## Interval between consecutive evaluations.
          ##
          evaluationInterval: 30s

          ## Resource limits & requests
          ##
          resources:
            requests:
              memory: 10Gi
            limits:
              memory: 10Gi

          ## Prometheus StorageSpec for persistent data
          ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/user-guides/storage.md
          ##
          storageSpec: {}
          #  volumeClaimTemplate:
          #    spec:
          #      storageClassName: gluster
          #      accessModes: ["ReadWriteOnce"]
          #      resources:
          #        requests:
          #          storage: 50Gi
          #    selector: {}

          ## AdditionalScrapeConfigs allows specifying additional Prometheus scrape configurations. Scrape configurations
          ## are appended to the configurations generated by the Prometheus Operator. Job configurations must have the form
          ## as specified in the official Prometheus documentation:
          ## https://prometheus.io/docs/prometheus/latest/configuration/configuration/#<scrape_config>. As scrape configs are
          ## appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility
          ## to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible
          ## scrape configs are going to break Prometheus after the upgrade.
          ##
          additionalScrapeConfigs:
          - job_name: redis_exporter
            static_configs:
            - targets: ['prometheus-redis-exporter:9121']

          - job_name: tensorflow
            metrics_path: /monitoring/prometheus/metrics
            static_configs:
              - targets: ['tf-serving.deepcell:8501']
