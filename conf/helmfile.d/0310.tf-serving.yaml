helmDefaults:
  args:
    - "--wait"
    - "--timeout=600"
    - "--force"
    - "--reset-values"

releases:

################################################################################
## TensorFlow-Serving ##########################################################
################################################################################

#
# References:
#   - [web address of Helm chart's YAML file]
#
- name: "tf-serving"
  namespace: "deepcell"
  labels:
    chart: "tf-serving"
    component: "deepcell"
    namespace: "deepcell"
    vendor: "vanvalenlab"
    default: "true"
  chart: '{{ env "CHARTS_PATH" | default "/conf/charts" }}/tf-serving'
  version: "0.1.0"
  values:
    - replicas: 0

      image:
        repository: "vanvalenlab/kiosk-tf-serving"
        tag: "0.1"
        pullPolicy: "Always"

      resources:
        requests:
          nvidia.com/gpu: 1
          cpu: 500m
          memory: 3.5Gi
        limits:
          nvidia.com/gpu: 1
          # cpu: 100m
          # memory: 2048Mi

      service:
        type: "ClusterIP"

        httpIngressEnabled: true
        internalHttpPort: 8501
        httpTargetPort: 8501
        externalHttpPort: 8501

        grpcIngressEnabled: true
        internalGrpcPort: 8500
        grpcTargetPort: 8500
        externalGrpcPort: 8500

        httpsIngressEnabled: false

        annotations:
          prometheus.io/path: /monitoring/prometheus/metrics
          prometheus.io/port: "8501"
          prometheus.io/scrape: "true"

      annotations:
        prometheus.io/path: /monitoring/prometheus/metrics
        prometheus.io/port: "8501"
        prometheus.io/scrape: "true"

      nodeSelector:
{{ if eq (env "CLOUD_PROVIDER" | default "aws") "aws" }}
        beta.kubernetes.io/instance-type: '{{ env "AWS_GPU_MACHINE_TYPE" | default "p2.xlarge" }}'
{{ else }}
        cloud.google.com/gke-accelerator: '{{ env "PREDICTION_GPU_TYPE" | default "nvidia-tesla-k80" }}'
        cloud.google.com/gke-preemptible: "true"
{{ end }}

      env:
        PORT: 8500
        REST_API_PORT: 8501
        REST_API_TIMEOUT: 30000
        MODEL_CONFIG_FILE: /kiosk/tf-serving/models.conf
        BATCHING_CONFIG_FILE: /kiosk/tf-serving/batching_config.txt
        ENABLE_BATCHING: true
        MAX_BATCH_SIZE: 1
        BATCH_TIMEOUT_MICROS: 0
        MAX_ENQUEUED_BATCHES: 512
        GRPC_CHANNEL_ARGS: ""
        MODEL_PREFIX: models
        CLOUD_PROVIDER: '{{ env "CLOUD_PROVIDER" | default "aws" }}'
        TF_CPP_MIN_LOG_LEVEL: 0
        TF_SESSION_PARALLELISM: 0
        MONITORING_CONFIG_FILE: /kiosk/tf-serving/monitoring_config.txt
        PROMETHEUS_MONITORING_ENABLED: true
        PROMETHEUS_MONITORING_PATH: /monitoring/prometheus/metrics

      secrets:
        AWS_ACCESS_KEY_ID: '{{ env "AWS_ACCESS_KEY_ID" | default "NA" }}'
        AWS_SECRET_ACCESS_KEY: '{{ env "AWS_SECRET_ACCESS_KEY" | default "NA" }}'
        AWS_S3_BUCKET: '{{ env "AWS_S3_BUCKET" | default "NA" }}'
        GCLOUD_STORAGE_BUCKET: '{{ env "GKE_BUCKET" | default "NA" }}'
