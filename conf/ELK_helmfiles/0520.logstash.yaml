helmDefaults:
  wait: true
  timeout: 600
  force: true

repositories:
  # Stable repo of official helm charts
  - name: stable
    url: https://charts.helm.sh/stable

releases:

################################################################################
## Logstash ####################################################################
################################################################################

#
# References:
#   - https://github.com/helm/charts/tree/master/stable/logstash
#
- name: logstash
  namespace: elk
  labels:
    chart: logstash
    component: logstash
    namespace: elk
    vendor: elastic.co
    default: true
  chart: stable/logstash
  version: 2.4.3
  values:
    - replicaCount: 4

      service:
        type: ClusterIP
        ports:
          beats:
            port: 5044
            targetPort: beats
            protocol: TCP

      ports:
        - name: beats
          containerPort: 5044
          protocol: TCP

      resources:
        # limits:
        #  cpu: 100m
        #  memory: 128Mi
        requests:
         cpu: 150m
         memory: 1536Mi

      nodeSelector:
        logstash: "yes"

      tolerations:
      - key: logstash
        operator: Exists
        effect: NoSchedule

      livenessProbe:
        httpGet:
          path: /
          port: monitor
        initialDelaySeconds: 30
        # periodSeconds: 30
        # timeoutSeconds: 30
        # failureThreshold: 6
        # successThreshold: 1

      readinessProbe:
        httpGet:
          path: /
          port: monitor
        initialDelaySeconds: 30
        # periodSeconds: 30
        # timeoutSeconds: 30
        # failureThreshold: 6
        # successThreshold: 1

      persistence:
        enabled: true
        ## logstash data Persistent Volume Storage Class
        ## If defined, storageClassName: <storageClass>
        ## If set to "-", storageClassName: "", which disables dynamic provisioning
        ## If undefined (the default) or set to null, no storageClassName spec is
        ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
        ##   GKE, AWS & OpenStack)
        ##
        # storageClass: "-"
        accessMode: ReadWriteOnce
        size: 2Gi

      exporter:
        logstash:
          enabled: false

      elasticsearch:
        host: elasticsearch-client
        port: 9200

      ## Patterns for filters.
      ## Each YAML heredoc will become a separate pattern file.
      patterns:
        # main: |-
        #   TESTING {"foo":.*}$

      ## NOTE: To achieve multiple pipelines with this chart, current best practice
      ## is to maintain one pipeline per chart release. In this way configuration is
      ## simplified and pipelines are more isolated from one another.

      inputs:
        main: |-
          input {
            beats {
              port => 5044
            }
          }

      ## Examples for grok matches, in order:
      ## All filters were tested against the examples using http://grokdebug.herokuapp.com/
      ## Filter 1: Redis-consumer Storage Class Messages
      ## [2019-03-28 22:43:15,521]:[DEBUG]:[GoogleStorage]: Downloaded /tmp/tmp0dzilK/directupload_watershednuclearnofgbg41f16_0_watershed_0_benchmarking100000special_image_0.png from bucket deepcell-output-benchmarking3 in 0.195045948029 seconds.
      ## [2019-03-28 22:47:23,088]:[DEBUG]:[GoogleStorage]: Uploaded /tmp/tmpDZH9Sk/8e527bc296ea68aed57795ae33c76ae9.zip to bucket deepcell-output-benchmarking3 in 0.411799907684 seconds.
      ## Filter 2: Redis-consumer gRPC Messages
      ## [2019-03-28 22:43:16,210]:[DEBUG]:[PredictClient]: gRPC TensorFlowServingRequest finished in 0.455268859863 seconds.
      ## [2019-03-28 22:43:18,231]:[DEBUG]:[PredictClient]: gRPC TensorFlowServingProtobufConversion took 2.01989483833 seconds.
      ## [2019-03-28 22:47:22,407]:[INFO]:[ProcessClient]: gRPC DataProcessingStreamRequest of 5529600 bytes finished in 0.960053920746 seconds.
      ## NOT BEING MATCHED: [2019-03-28 22:47:22,408]:[INFO]:[ProcessClient]: gRPC DataProcessingStreamConversion from 5529600 bytes to a numpy array of shape (1, 1280, 1080, 1) in 7.41481781006e-05 seconds.
      ## Filter 3: Redis-consumer Consumer Messages
      ## [2019-03-28 22:43:18,241]:[DEBUG]:[ImageFileConsumer]: Segmented key predict_e3700d5ae0f1478d81f21a72d685469e_directupload_watershednuclearnofgbg41f16_0_watershed_0_benchmarking100000special_image_059037.png (model watershednuclearnofgbg41f16:0, preprocessing: None, postprocessing: watershed) (0 retries) in 2.67694497108 seconds.
      ## [2019-03-28 22:47:22,409]:[DEBUG]:[ImageFileConsumer]: Post-processed key predict_10e4553738b6428bae025ec4c1da9160_directupload_watershednuclearnofgbg41f16_0_watershed_0_benchmarking100000special_image_042604.png (model watershednuclearnofgbg41f16:0, preprocessing: None, postprocessing: watershed) (0 retries)  in 0.964694023132 seconds.
      ## [2019-03-28 22:47:23,109]:[DEBUG]:[ImageFileConsumer]: Consumed key predict_10e4553738b6428bae025ec4c1da9160_directupload_watershednuclearnofgbg41f16_0_watershed_0_benchmarking100000special_image_042604.png (model watershednuclearnofgbg41f16:0, preprocessing: None, postprocessing: watershed) (0 retries) in 6.4265601635 seconds.
      filters:
        main: |-
          filter {
            if "redis-consumer" in [kubernetes][pod][name] {
              grok {
                match => {
                  "message" => [
                    "\[%{NOTSPACE:date} %{NOTSPACE:time}\]:\[%{LOGLEVEL:loglevel}\]:\[%{NOTSPACE:module}\]: %{NOTSPACE:redis_consumer_action} %{NOTSPACE:redis_consumer_filename} (from|to) bucket %{NOTSPACE:redis_consumer_bucket} in %{NUMBER:redis_consumer_seconds:float} seconds.",
                    "\[%{NOTSPACE:date} %{NOTSPACE:time}\]:\[%{LOGLEVEL:loglevel}\]:\[%{NOTSPACE:module}\]: gRPC %{NOTSPACE:redis_consumer_action} (of %{NUMBER:redis_consumer_bytes:int} bytes )?(finished in|took) %{NUMBER:redis_consumer_seconds:float} seconds.",
                    "\[%{NOTSPACE:date} %{NOTSPACE:time}\]:\[%{LOGLEVEL:loglevel}\]:\[%{NOTSPACE:module}\]: %{NOTSPACE:redis_consumer_action} key %{NOTSPACE:redis_consumer_key} \(model %{NOTSPACE:redis_consumer_model}, preprocessing: %{NOTSPACE:redis_consumer_preprocessing_function}, postprocessing: %{NOTSPACE:redis_consumer_postprocessing_function}\) \(%{NUMBER:redis_consumer_retries:int} retries\) ( )?in %{NUMBER:redis_consumer_seconds:float} seconds."
                  ]
                }
              }
            }
          }

      outputs:
        main: |-
          output {
            # stdout { codec => rubydebug }
            elasticsearch {
              hosts => ["${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}"]
              manage_template => false
              index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
            }
          }
